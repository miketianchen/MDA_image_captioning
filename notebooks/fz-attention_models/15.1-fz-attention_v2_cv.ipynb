{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BaIK-bqzFhja"
   },
   "source": [
    "## Image Captioning with Pytorch\n",
    "\n",
    "The following contents are modified from MDS DSCI 575 lecture 8 demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2p8iXQygqRN"
   },
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "from torchsummary import summary\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from nltk.translate import bleu_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "sys.path.append('../../scr/evaluation')\n",
    "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "from pycocoevalcap.bleu.bleu import Bleu\n",
    "from pycocoevalcap.meteor.meteor import Meteor\n",
    "from pycocoevalcap.rouge.rouge import Rouge\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.spice.spice import Spice\n",
    "from pycocoevalcap.usc_sim.usc_sim import usc_sim\n",
    "import subprocess\n",
    "\n",
    "\n",
    "START = \"startseq\"\n",
    "STOP = \"endseq\"\n",
    "EPOCHS = 10\n",
    "AWS = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vmle0AXFBSdk"
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# import gc \n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "2W5oWBSofR7d",
    "outputId": "a0cc11ef-0e70-470c-e4b5-53912f21e341"
   },
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m:>02}:{s:>05.2f}\"\n",
    "        \n",
    "if AWS:\n",
    "    root_captioning = \"../../data\"\n",
    "else:\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive', force_remount=True)\n",
    "        root_captioning = \"/content/drive/My Drive/data\"\n",
    "        COLAB = True\n",
    "        print(\"Note: using Google CoLab\")\n",
    "    except:\n",
    "        print(\"Note: not using Google CoLab\")\n",
    "        COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VlBS8URRgaOo"
   },
   "source": [
    "### Clean/Build Dataset\n",
    "\n",
    "- Read captions\n",
    "- Preprocess captions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ra-d7BLlf1nC"
   },
   "outputs": [],
   "source": [
    "def get_img_info(name, num=np.inf):\n",
    "    \"\"\"\n",
    "    Returns img paths and captions\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    name: str\n",
    "        the json file name\n",
    "    num: int (default: np.inf)\n",
    "        the number of observations to get\n",
    "\n",
    "    Return:\n",
    "    --------\n",
    "    list, dict, int\n",
    "        img paths, corresponding captions, max length of captions\n",
    "    \"\"\"\n",
    "    img_path = []\n",
    "    caption = [] \n",
    "    max_length = 0\n",
    "    if AWS:\n",
    "        with open(f'{root_captioning}/json/{name}.json', 'r') as json_data:\n",
    "            data = json.load(json_data)\n",
    "            for filename in data.keys():\n",
    "                if num is not None and len(caption) == num:\n",
    "                    break\n",
    "                img_path.append(\n",
    "                    f'{root_captioning}/{name}/{filename}'\n",
    "                )\n",
    "                sen_list = []\n",
    "                for sentence in data[filename]['sentences']:\n",
    "                    max_length = max(max_length, len(sentence['tokens']))\n",
    "                    sen_list.append(sentence['raw'])\n",
    "\n",
    "                caption.append(sen_list)    \n",
    "    else:            \n",
    "        with open(f'{root_captioning}/interim/{name}.json', 'r') as json_data:\n",
    "            data = json.load(json_data)\n",
    "            for set_name in ['rsicd', 'ucm']:\n",
    "                for filename in data[set_name].keys():\n",
    "                    if num is not None and len(caption) == num:\n",
    "                        break\n",
    "\n",
    "                    img_path.append(\n",
    "                        f'{root_captioning}/raw/imgs/{set_name}/{filename}'\n",
    "                    )\n",
    "                    sen_list = []\n",
    "                    for sentence in data[set_name][filename]['sentences']:\n",
    "                        max_length = max(max_length, len(sentence['tokens']))\n",
    "                        sen_list.append(sentence['raw'])\n",
    "\n",
    "                    caption.append(sen_list)\n",
    "    \n",
    "    return img_path, caption, max_length            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMUxfR9xKICI"
   },
   "outputs": [],
   "source": [
    "# get img path and caption list\n",
    "# # only test 800 train samples and 200 valid samples\n",
    "# train_paths, train_descriptions, max_length_train = get_img_info('train', 800)\n",
    "# test_paths, test_descriptions, max_length_test = get_img_info('valid', 200)\n",
    "\n",
    "train_paths, train_descriptions, max_length_train = get_img_info('train')\n",
    "test_paths, test_descriptions, max_length_test = get_img_info('valid')\n",
    "max_length = max(max_length_train, max_length_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10416 images\n",
      "There are 2912 unique words (vocab)\n",
      "The maximum length of captions with start and stop token is 36.\n"
     ]
    }
   ],
   "source": [
    "all_paths = train_paths.copy()\n",
    "all_paths.extend(test_paths.copy())\n",
    "all_paths = np.array(all_paths)\n",
    "\n",
    "all_descriptions = train_descriptions.copy()\n",
    "all_descriptions.extend(test_descriptions.copy())\n",
    "all_descriptions = np.array(all_descriptions)\n",
    "\n",
    "captions = all_descriptions.copy()\n",
    "max_length_all = max(max_length_train, max_length_test)\n",
    "max_length = max_length_all + 2\n",
    "      \n",
    "lex = set()\n",
    "for sen in all_descriptions:\n",
    "    [lex.update(d.split()) for d in sen]\n",
    "    \n",
    "# add a start and stop token at the beginning/end\n",
    "for v in all_descriptions:\n",
    "    for d in range(len(v)):\n",
    "        v[d] = f'{START} {v[d]} {STOP}'\n",
    "        \n",
    "print(f'There are {len(all_paths)} images') \n",
    "print(f'There are {len(lex)} unique words (vocab)')\n",
    "print(f'The maximum length of captions with start and stop token is {max_length}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2ZQ_Cl71YM55",
    "outputId": "93c0761e-95bf-4e7e-9313-a26106a48327"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../s3/valid/rsicd_park_33.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paths[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "id": "v3_PCjddHcUe",
    "outputId": "a8170e9a-51c0-44bc-94ea-d2a7eb8702ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['startseq a vast artificial lake was built in the park . endseq',\n",
       "       'startseq there are many residential areas near the park . endseq',\n",
       "       'startseq there are many residential areas near the park . endseq',\n",
       "       'startseq a vast artificial lake was built in the park . endseq',\n",
       "       'startseq a vast artificial lake was built in the park . endseq'],\n",
       "      dtype='<U184')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_descriptions[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vtIIFt4m6pTv"
   },
   "source": [
    "### Loading Wikipedia2vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IY_9XZ4Hec73",
    "outputId": "22d9061d-9070-4212-b7eb-989a9b7631a3"
   },
   "outputs": [],
   "source": [
    "# read the embedding matrix \n",
    "with open(f'{root_captioning}/enwiki_20180420_2338_words_500d.json', 'r', encoding='utf-8') as file:\n",
    "    embeddings_index = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(descriptions, word_count_threshold=10):\n",
    "\n",
    "    captions = []\n",
    "    for val in descriptions:\n",
    "        for cap in val:\n",
    "            captions.append(cap)\n",
    "    print(f'There are {len(captions)} captions')\n",
    "    \n",
    "    word_counts = {}\n",
    "    nsents = 0\n",
    "    for sent in captions:\n",
    "        nsents += 1\n",
    "        for w in sent.split(' '):\n",
    "            word_counts[w] = word_counts.get(w, 0) + 1\n",
    "\n",
    "    vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
    "    print('preprocessed words %d ==> %d' % (len(word_counts), len(vocab)))\n",
    "    return vocab\n",
    "\n",
    "def get_word_dict(vocab):\n",
    "    \n",
    "    idxtoword = {}\n",
    "    wordtoidx = {}\n",
    "\n",
    "    ix = 1\n",
    "    for w in vocab:\n",
    "        wordtoidx[w] = ix\n",
    "        idxtoword[ix] = w\n",
    "        ix += 1\n",
    "\n",
    "    return idxtoword, wordtoidx\n",
    "\n",
    "def get_vocab_size(idxtoword):\n",
    "    \n",
    "    print(f'The vocabulary size is {len(idxtoword) + 1}.')\n",
    "    return len(idxtoword) + 1\n",
    "\n",
    "\n",
    "def get_embeddings(embeddings_index, vocab_size, embedding_dim, wordtoidx):\n",
    "\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    count = 0\n",
    "\n",
    "    for word, i in wordtoidx.items():\n",
    "\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            count += 1\n",
    "            # Words not found in the embedding index will be all zeros\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    print(f'{count} out of {vocab_size} words are found in the pre-trained matrix.')            \n",
    "    print(f'The size of embedding_matrix is {embedding_matrix.shape}')\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYH3-S2n82MN"
   },
   "source": [
    "### Building the Neural Network\n",
    "\n",
    "An embedding matrix is built from Glove.  This will be directly copied to the weight matrix of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w33HKER-vZ7U",
    "outputId": "8c21728f-002c-4050-8a01-498dadf69f0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWOP58lrtGwt"
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained=True):\n",
    "        \"\"\"\n",
    "        Initializes a CNNModel\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        pretrained: bool (default: True)\n",
    "            use pretrained model if True\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        # inception v3 expects (299, 299) sized images\n",
    "        self.model = models.inception_v3(pretrained=pretrained, aux_logits=False)\n",
    "        # remove the classification layer\n",
    "        self.model =\\\n",
    "        nn.Sequential(\n",
    "            *(list(self.model.children())[: 3]),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            *(list(self.model.children())[3: 5]),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            *(list(self.model.children())[5: -1])\n",
    "        )\n",
    "\n",
    "        self.input_size = 299\n",
    "\n",
    "    def forward(self, img_input, train=False):\n",
    "        \"\"\"\n",
    "        forward of the CNNModel\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        img_input: torch.Tensor\n",
    "            the image matrix\n",
    "        train: bool (default: False)\n",
    "            use the model only for feature extraction if False\n",
    "\n",
    "        Return:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            image feature matrix\n",
    "        \"\"\"\n",
    "        if not train:\n",
    "          # set the model to evaluation model\n",
    "          self.model.eval()\n",
    "\n",
    "        # N x 3 x 299 x 299\n",
    "        features = self.model(img_input)\n",
    "        # N x 2048 x 8 x 8\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_size, atten_size=512):\n",
    "        \"\"\"\n",
    "        Initializes a AttentionModel\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        cnn_type: str\n",
    "            the CNN type, either 'vgg16' or 'inception_v3'\n",
    "        pretrained: bool (default: True)\n",
    "            use pretrained model if True\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super(AttentionModel, self).__init__()\n",
    "\n",
    "        self.dense1 = nn.Linear(hidden_size, atten_size)\n",
    "        self.dense2 = nn.Linear(embedding_dim, atten_size)\n",
    "        self.dense3 = nn.Linear(atten_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, img_features, h):\n",
    "        \"\"\"\n",
    "        forward of the AttentionModel\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        img_input: torch.Tensor\n",
    "            the image matrix\n",
    "        train: bool (default: False)\n",
    "            use the model only for feature extraction if False\n",
    "\n",
    "        Return:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            image feature matrix\n",
    "        \"\"\"\n",
    "        # N x hidden_size\n",
    "        h_a = self.dense1(h)\n",
    "        # N x atten_size\n",
    "\n",
    "        # N x 64 x embedding_dim\n",
    "        img_a = self.dense2(img_features)  \n",
    "        # N x 64 x atten_size\n",
    "\n",
    "        attention =\\\n",
    "        self.dense3(\n",
    "            self.relu(\n",
    "                h_a.unsqueeze(1) + img_a\n",
    "            )\n",
    "        ).squeeze(2)\n",
    "        # N x 64\n",
    "\n",
    "        attention_weights = F.softmax(attention, dim=1)\n",
    "        # N x 64\n",
    "\n",
    "        return attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5uWZ8QOOXtUM"
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        feature_size,\n",
    "        vocab_size,\n",
    "        embedding_dim, \n",
    "        hidden_size=256,\n",
    "        atten_size=512,\n",
    "        embedding_matrix=None, \n",
    "        embedding_train=False\n",
    "    ):\n",
    "      \n",
    "        \"\"\"\n",
    "        Initializes a RNNModel\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        feature_size: int\n",
    "            the number of features in the image matrix\n",
    "        vocab_size: int\n",
    "            the size of the vocabulary\n",
    "        embedding_dim: int\n",
    "            the number of features in the embedding matrix\n",
    "        hidden_size: int (default: 256)\n",
    "            the size of the hidden state in LSTM\n",
    "        embedding_matrix: torch.Tensor (default: None)\n",
    "            if not None, use this matrix as the embedding matrix\n",
    "        embedding_train: bool (default: False)\n",
    "            not train the embedding matrix if False\n",
    "        \"\"\"\n",
    "\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding =\\\n",
    "        nn.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim, \n",
    "            padding_idx=0\n",
    "        )\n",
    "\n",
    "        if embedding_matrix is not None:\n",
    "\n",
    "            self.embedding.load_state_dict({\n",
    "                'weight': torch.FloatTensor(embedding_matrix)\n",
    "            })\n",
    "            self.embedding.weight.requires_grad = embedding_train\n",
    "\n",
    "\n",
    "\n",
    "        self.attention =\\\n",
    "        AttentionModel(\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            atten_size\n",
    "        )\n",
    "\n",
    "\n",
    "        self.lstm =\\\n",
    "        nn.LSTMCell(\n",
    "#             embedding_dim + embedding_dim, \n",
    "            embedding_dim,\n",
    "            hidden_size, \n",
    "            bias=True\n",
    "        )\n",
    "        \n",
    "        self.dense1 = nn.Linear(feature_size, embedding_dim)\n",
    "        self.dense2 = nn.Linear(hidden_size, embedding_dim)\n",
    "        self.dense3 = nn.Linear(feature_size, hidden_size)\n",
    "        self.dense4 = nn.Linear(feature_size, hidden_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        x = torch.autograd.Variable(next(self.parameters()).data.new(batch_size, self.hidden_size))\n",
    "        return x\n",
    "\n",
    "    def forward(self, img_features, captions):\n",
    "        \"\"\"\n",
    "        forward of the RNNModel\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        img_features: torch.Tensor \n",
    "            the image feature matrix\n",
    "            (N x feature_size(2048) x 8 x 8)\n",
    "        captions: torch.Tensor \n",
    "            the padded caption matrix\n",
    "            (N x seq_len)\n",
    "\n",
    "        Return:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            word probabilities for each position\n",
    "        \"\"\"\n",
    "\n",
    "        # N = batch_size\n",
    "        batch_size = captions.size(0)\n",
    "        seq_len = captions.size(1)\n",
    "\n",
    "        # N x feature_size(2048) x 8 x 8\n",
    "        img_features = img_features.view(\n",
    "            batch_size, self.feature_size, -1\n",
    "        ).permute(0, 2, 1)\n",
    "        # N x 64 x feature_size(2048)\n",
    "\n",
    "        # h = self.init_hidden(batch_size).to(device)\n",
    "        # c = self.init_hidden(batch_size).to(device)\n",
    "        # # N x hidden_size\n",
    "\n",
    "        # N x 64 x feature_size(2048)\n",
    "        h = self.dense3(img_features.mean(dim=1))\n",
    "        c = self.dense4(img_features.mean(dim=1))\n",
    "        # N x hidden_size\n",
    "\n",
    "        # N x seq_len\n",
    "        embed = self.dropout(self.embedding(captions))\n",
    "        # N x seq_len x embedding_dim     \n",
    "\n",
    "        # N x 64 x feature_size(2048)\n",
    "        img_features = self.dropout(self.relu(self.dense1(img_features)))\n",
    "        # N x 64 x embedding_dim\n",
    "\n",
    "        outputs =\\\n",
    "        torch.zeros(\n",
    "            batch_size,\n",
    "            seq_len, \n",
    "            self.hidden_size\n",
    "        ).to(device)\n",
    "\n",
    "        all_attention_weights =\\\n",
    "        torch.zeros(\n",
    "            batch_size,\n",
    "            seq_len, \n",
    "            img_features.shape[1]\n",
    "        ).to(device)\n",
    "        \n",
    "        for i in range(seq_len):\n",
    "            \n",
    "            attention_weights = self.attention(img_features, h)\n",
    "            # N x 64\n",
    "\n",
    "            # weighted sum of img_features\n",
    "            weighted = (img_features * attention_weights.unsqueeze(2)).sum(dim=1)\n",
    "            # N x embedding_dim\n",
    "\n",
    "            # gating scalar\n",
    "            # N x hidden_size\n",
    "            gate = self.sigmoid(self.dense2(h))\n",
    "            # N x embedding_dim\n",
    "\n",
    "            weighted = gate * weighted\n",
    "\n",
    "            h, c =\\\n",
    "            self.lstm(\n",
    "                embed[:, i, :] + weighted, \n",
    "               (h, c)\n",
    "            )\n",
    "            # h: N x hidden_size\n",
    "            # c: N x hidden_size\n",
    " \n",
    "            outputs[:, i, :] = h\n",
    "            all_attention_weights[:, i, :] = attention_weights\n",
    "\n",
    "        return outputs, all_attention_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzigDNU6jEly"
   },
   "outputs": [],
   "source": [
    "class CaptionModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab_size, \n",
    "        embedding_dim, \n",
    "        hidden_size=256,\n",
    "        atten_size=512,\n",
    "        embedding_matrix=None, \n",
    "        embedding_train=False\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        Initializes a CaptionModel\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        vocab_size: int\n",
    "            the size of the vocabulary\n",
    "        embedding_dim: int\n",
    "            the number of features in the embedding matrix\n",
    "        hidden_size: int (default: 256)\n",
    "            the size of the hidden state in LSTM\n",
    "        embedding_matrix: torch.Tensor (default: None)\n",
    "            if not None, use this matrix as the embedding matrix\n",
    "        embedding_train: bool (default: False)\n",
    "            not train the embedding matrix if False\n",
    "        \"\"\"    \n",
    "        super(CaptionModel, self).__init__() \n",
    "\n",
    "        # set feature_size based on cnn_type\n",
    "        self.feature_size = 2048\n",
    "\n",
    "        self.decoder = RNNModel(\n",
    "            self.feature_size,\n",
    "            vocab_size, \n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            atten_size,\n",
    "            embedding_matrix,\n",
    "            embedding_train\n",
    "        )\n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.dense1 = nn.Linear(hidden_size, vocab_size) \n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.dense2 = nn.Linear(512, vocab_size) \n",
    "\n",
    "    # def forward(self, captions):\n",
    "    def forward(self, img_features, captions):\n",
    "        \"\"\"\n",
    "        forward of the CaptionModel\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        img_features: torch.Tensor \n",
    "            the image feature matrix\n",
    "            (N x feature_size(2048) x 8 x 8)\n",
    "        captions: torch.Tensor \n",
    "            the padded caption matrix\n",
    "            (N x seq_len)\n",
    "\n",
    "        Return:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            word probabilities for each position\n",
    "        \"\"\"\n",
    "    \n",
    "        decoder_out, all_attention_weights = self.decoder(img_features, captions)\n",
    "\n",
    "        # add up decoder outputs and image features\n",
    "        outputs = self.dense1(decoder_out)\n",
    "\n",
    "        return outputs, all_attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wCSzCGtB8-KM"
   },
   "source": [
    "### Train the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0ihg_mBrF-b"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip, vocab_size):\n",
    "    \"\"\"\n",
    "    train the CaptionModel\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model: CaptionModel\n",
    "        a CaptionModel instance\n",
    "    iterator: torch.utils.data.dataloader\n",
    "        a PyTorch dataloader\n",
    "    optimizer: torch.optim\n",
    "        a PyTorch optimizer \n",
    "    criterion: nn.CrossEntropyLoss\n",
    "        a PyTorch criterion \n",
    "\n",
    "    Return:\n",
    "    --------\n",
    "    float\n",
    "        average loss\n",
    "    \"\"\"\n",
    "    model.train()    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for img_features, captions in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # for each caption, the end word is not passed for training\n",
    "        outputs, all_attention_weights = model(\n",
    "            img_features.to(device),\n",
    "            captions[:, :-1].to(device)\n",
    "        )\n",
    "\n",
    "        loss = criterion(\n",
    "            outputs.view(-1, vocab_size), \n",
    "            captions[:, 1:].flatten().to(device)\n",
    "        ) + ((1. - all_attention_weights.sum(dim=1)) ** 2).mean()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpKuO9EPwcoc"
   },
   "outputs": [],
   "source": [
    "class SampleDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        descriptions,\n",
    "        imgs,\n",
    "        wordtoidx,\n",
    "        max_length\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a SampleDataset\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        descriptions: list\n",
    "            a list of captions\n",
    "        imgs: numpy.ndarray\n",
    "            the image features\n",
    "        wordtoidx: dict\n",
    "            the dict to get word index\n",
    "        max_length: int\n",
    "            all captions will be padded to this size\n",
    "        \"\"\"        \n",
    "        self.imgs = imgs\n",
    "        self.descriptions = descriptions\n",
    "        self.wordtoidx = wordtoidx\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the batch size\n",
    "\n",
    "        Return:\n",
    "        --------\n",
    "        int\n",
    "            the batch size\n",
    "        \"\"\"\n",
    "        # return len(self.descriptions)\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Prepare data for each image\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        idx: int\n",
    "          the index of the image to process\n",
    "\n",
    "        Return:\n",
    "        --------\n",
    "        list, list, list\n",
    "            [5 x image feature matrix],\n",
    "            [five padded captions for this image]\n",
    "            [the length of each caption]\n",
    "        \"\"\"\n",
    "\n",
    "        img = self.imgs[idx // 5]\n",
    "        # convert each word into a list of sequences.\n",
    "        seq = [self.wordtoidx[word] for word \n",
    "               in self.descriptions[idx // 5][idx % 5].split(' ')\n",
    "               if word in self.wordtoidx]\n",
    "        # pad the sequence with 0 on the right side\n",
    "        in_seq = np.pad(\n",
    "            seq, \n",
    "            (0, max_length - len(seq)),\n",
    "            mode='constant',\n",
    "            constant_values=(0, 0)\n",
    "            )\n",
    "\n",
    "        return img, in_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-mdGlavHoNi"
   },
   "outputs": [],
   "source": [
    "def init_weights(model, embedding_pretrained=True):\n",
    "    \"\"\"\n",
    "    Initialize weights and bias in the model\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model: CaptionModel\n",
    "      a CaptionModel instance\n",
    "    embedding_pretrained: bool (default: True)\n",
    "        not initialize the embedding matrix if True\n",
    "    \"\"\"  \n",
    "  \n",
    "    for name, param in model.named_parameters():\n",
    "        if embedding_pretrained and 'embedding' in name:\n",
    "            continue\n",
    "        elif 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gYh9dzaSms1T"
   },
   "outputs": [],
   "source": [
    "def encode_image(model, img_path):\n",
    "    \"\"\"\n",
    "    Process the images to extract features\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model: CNNModel\n",
    "      a CNNModel instance\n",
    "    img_path: str\n",
    "        the path of the image\n",
    " \n",
    "    Return:\n",
    "    --------\n",
    "    torch.Tensor\n",
    "        the extracted feature matrix from CNNModel\n",
    "    \"\"\"  \n",
    "\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # Perform preprocessing needed by pre-trained models\n",
    "    preprocessor = transforms.Compose([\n",
    "        transforms.Resize(model.input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    img = preprocessor(img)\n",
    "    # Expand to 2D array\n",
    "    img = img.view(1, *img.shape)\n",
    "    # Call model to extract the smaller feature set for the image.\n",
    "    x = model(img.to(device), False) \n",
    "    # Shape to correct form to be accepted by LSTM captioning network.\n",
    "    x = np.squeeze(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n93pfnZhg1KX"
   },
   "outputs": [],
   "source": [
    "def extract_img_features(img_paths, model):\n",
    "    \"\"\"\n",
    "    Extracts, stores and returns image features\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    img_paths: list\n",
    "        the paths of images\n",
    "    model: CNNModel (default: None)\n",
    "      a CNNModel instance\n",
    "\n",
    "    Return:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        the extracted image feature matrix from CNNModel\n",
    "    \"\"\" \n",
    "\n",
    "    start = time()\n",
    "    img_features = []\n",
    "\n",
    "    for image_path in tqdm(img_paths):\n",
    "        img_features.append(\n",
    "            encode_image(model, image_path).cpu().data.numpy()\n",
    "        )\n",
    "\n",
    "    print(f\"\\nGenerating set took: {hms_string(time()-start)}\")\n",
    "\n",
    "    return img_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fTNcjLMh7sw"
   },
   "outputs": [],
   "source": [
    "def get_train_test(\n",
    "    encoder,\n",
    "    train_paths,\n",
    "    test_paths\n",
    "):\n",
    "\n",
    "    train_img_features = extract_img_features(\n",
    "        train_paths,\n",
    "        encoder\n",
    "    )\n",
    "\n",
    "    test_img_features = extract_img_features(\n",
    "        test_paths,\n",
    "        encoder\n",
    "    )\n",
    "    return train_img_features, test_img_features\n",
    "\n",
    "def get_train_dataloader(\n",
    "    train_descriptions, \n",
    "    train_img_features,\n",
    "    wordtoidx,\n",
    "    max_length,\n",
    "    batch_size=200\n",
    "):\n",
    "    train_dataset = SampleDataset(\n",
    "        train_descriptions,\n",
    "        train_img_features,\n",
    "        wordtoidx,\n",
    "        max_length\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    return train_loader\n",
    "\n",
    "def train_model(\n",
    "    train_loader,\n",
    "    vocab_size,\n",
    "    embedding_dim, \n",
    "    embedding_matrix,\n",
    "    hidden_size=256,\n",
    "):\n",
    "\n",
    "    caption_model = CaptionModel(\n",
    "        vocab_size, \n",
    "        embedding_dim, \n",
    "        hidden_size=500,\n",
    "        atten_size=256,\n",
    "        embedding_matrix=embedding_matrix, \n",
    "        embedding_train=True\n",
    "    )\n",
    "\n",
    "    init_weights(\n",
    "        caption_model,\n",
    "        embedding_pretrained=True\n",
    "    )\n",
    "\n",
    "    caption_model.to(device)\n",
    "\n",
    "    # we will ignore the pad token in true target set\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        caption_model.parameters(), \n",
    "        lr=0.01\n",
    "    )\n",
    "\n",
    "    clip = 1\n",
    "    start = time()\n",
    "\n",
    "    for i in tqdm(range(EPOCHS * 3)):\n",
    "\n",
    "        loss = train(caption_model, train_loader, optimizer, criterion, clip, vocab_size)\n",
    "        print(loss)\n",
    "\n",
    "    # reduce the learning rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = 1e-4\n",
    "\n",
    "    for i in tqdm(range(EPOCHS * 5)):\n",
    "\n",
    "        loss = train(caption_model, train_loader, optimizer, criterion, clip, vocab_size)\n",
    "        print(loss)\n",
    "    return caption_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5WoWWbc9Y-g"
   },
   "outputs": [],
   "source": [
    "def generateCaption(\n",
    "    model, \n",
    "    img_features,\n",
    "    max_length,\n",
    "    vocab_size,\n",
    "    wordtoidx,\n",
    "    idxtoword\n",
    "):\n",
    "    in_text = START\n",
    "\n",
    "    for i in range(max_length):\n",
    "\n",
    "        sequence = [wordtoidx[w] for w in in_text.split() if w in wordtoidx]\n",
    "        sequence = np.pad(sequence, (0, max_length - len(sequence)),\n",
    "                          mode='constant', constant_values=(0, 0))\n",
    "        model.eval()\n",
    "        yhat, _ = model(\n",
    "            torch.FloatTensor(img_features)\\\n",
    "            .view(-1, model.feature_size).to(device),\n",
    "            torch.LongTensor(sequence).view(-1, max_length).to(device)\n",
    "        )\n",
    "\n",
    "        yhat = yhat.view(-1, vocab_size).argmax(1)\n",
    "        word = idxtoword[yhat.cpu().data.numpy()[i]]\n",
    "        in_text += ' ' + word\n",
    "        if word == STOP:\n",
    "            break\n",
    "    final = in_text.split()\n",
    "    final = final[1 : -1]\n",
    "    final = ' '.join(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(ref_data, results):\n",
    "    \"\"\"\n",
    "    Computes evaluation metrics of the model results against the human annotated captions\n",
    "    \n",
    "    Parameters:\n",
    "    ------------\n",
    "    ref_data: dict\n",
    "        a dictionary containing human annotated captions, with image name as key and a list of human annotated captions as values\n",
    "    \n",
    "    results: dict\n",
    "        a dictionary containing model generated caption, with image name as key and a generated caption as value\n",
    "        \n",
    "    Returns:\n",
    "    ------------\n",
    "    score_dict: a dictionary containing the overall average score for the model\n",
    "    \"\"\"\n",
    "    # download stanford nlp library\n",
    "    subprocess.call(['../../scr/evaluation/get_stanford_models.sh'])\n",
    "    \n",
    "    # format the inputs\n",
    "    gts = {}\n",
    "    res = {}\n",
    "\n",
    "    for imgId in range(len(ref_data)):\n",
    "        caption_list_sel = []\n",
    "        for i in range(5):\n",
    "            lst = {}\n",
    "            lst['caption'] = ref_data[imgId][i]\n",
    "            lst['image_id'] = imgId\n",
    "            lst['id'] = i\n",
    "            caption_list_sel.append(lst)\n",
    "        gts[imgId] = caption_list_sel\n",
    "\n",
    "        res[imgId] = [{'caption': results[imgId]}]\n",
    "        \n",
    "    # tokenize\n",
    "    print('tokenization...')\n",
    "    tokenizer = PTBTokenizer()\n",
    "    gts  = tokenizer.tokenize(gts)\n",
    "    res = tokenizer.tokenize(res)\n",
    "    \n",
    "    # compute scores\n",
    "    scorers = [\n",
    "        (Bleu(4), [\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"]),\n",
    "        (Meteor(),\"METEOR\"),\n",
    "        (Rouge(), \"ROUGE_L\"),\n",
    "        (Cider(), \"CIDEr\"),\n",
    "        (Spice(), \"SPICE\"),\n",
    "        (usc_sim(), \"USC_similarity\"),  \n",
    "        ]\n",
    "    score_dict = {}\n",
    "    for scorer, method in scorers:\n",
    "        print('computing %s score...'%(scorer.method()))\n",
    "        score, scores = scorer.compute_score(gts, res)\n",
    "        if type(method) == list:\n",
    "            for sc, scs, m in zip(score, scores, method):\n",
    "                score_dict[m] = sc\n",
    "        else:\n",
    "            score_dict[method] = score\n",
    "            \n",
    "    return score_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(\n",
    "    test_img_features, \n",
    "    model,\n",
    "    ref,\n",
    "    max_length,\n",
    "    vocab_size,\n",
    "    wordtoidx,\n",
    "    idxtoword\n",
    "):\n",
    "    # generate results\n",
    "    print('Generating captions...')\n",
    "    results = {}\n",
    "    for n in range(len(test_img_features)):\n",
    "        img_features = test_img_features[n]\n",
    "        generated = generateCaption(\n",
    "            model, \n",
    "            img_features,\n",
    "            max_length,\n",
    "            vocab_size,\n",
    "            wordtoidx,\n",
    "            idxtoword\n",
    "        )\n",
    "        results[n] = generated\n",
    "        \n",
    "    model_score = eval_model(ref, results)\n",
    "\n",
    "    return model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MAv_Bab17WeD"
   },
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (model): Sequential(\n",
       "    (0): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_type = 'inception_v3'\n",
    "encoder = CNNModel(pretrained=True)\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(train_index, test_index, count):\n",
    "    print('=' * 60)\n",
    "    print(f'Split {count}:')\n",
    "    print(f'Splitting data...')\n",
    "    \n",
    "    train_paths, test_paths = all_paths[train_index], all_paths[test_index]\n",
    "    train_descriptions, test_descriptions = all_descriptions[train_index], all_descriptions[test_index]\n",
    "    print(f'{len(train_paths)} images for training and {len(test_paths)} images for testing.')\n",
    "    \n",
    "    vocab = get_vocab(train_descriptions, word_count_threshold=10)\n",
    "    idxtoword, wordtoidx = get_word_dict(vocab)\n",
    "    vocab_size = get_vocab_size(idxtoword)\n",
    "    embedding_dim = 500\n",
    "    embedding_matrix = get_embeddings(embeddings_index, vocab_size, embedding_dim, wordtoidx) \n",
    "\n",
    "    print(f'Preparing dataloader...')\n",
    "    train_img_features, test_img_features = get_train_test(encoder, train_paths, test_paths)\n",
    "\n",
    "    train_loader = get_train_dataloader(\n",
    "        train_descriptions, \n",
    "        train_img_features,\n",
    "        wordtoidx,\n",
    "        max_length,\n",
    "        batch_size=1000\n",
    "    )\n",
    "\n",
    "    print(f'Training...')\n",
    "    caption_model = train_model(\n",
    "        train_loader,\n",
    "        vocab_size,\n",
    "        embedding_dim, \n",
    "        embedding_matrix,\n",
    "        hidden_size=500\n",
    "    )\n",
    "\n",
    "    \n",
    "    ref = captions[test_index]\n",
    "    model_score = evaluate_results(\n",
    "        test_img_features, \n",
    "        caption_model,\n",
    "        ref,\n",
    "        max_length,\n",
    "        vocab_size,\n",
    "        wordtoidx,\n",
    "        idxtoword\n",
    "    )\n",
    "    \n",
    "    return caption_model, model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "cv = [(train_index, test_index) for train_index, test_index in cv.split(all_paths)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Split 1:\n",
      "Splitting data...\n",
      "8332 images for training and 2084 images for testing.\n",
      "There are 41660 captions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed words 2659 ==> 884\n",
      "The vocabulary size is 885.\n",
      "793 out of 885 words are found in the pre-trained matrix.\n",
      "The size of embedding_matrix is (885, 500)\n",
      "Preparing dataloader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8332/8332 [03:38<00:00, 38.12it/s]\n",
      "  0%|          | 4/2084 [00:00<00:52, 39.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating set took: 0:03:38.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2084/2084 [00:55<00:00, 37.54it/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating set took: 0:00:55.51\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 1/30 [00:05<02:29,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.740195433298747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 2/30 [00:10<02:23,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.56277863184611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 3/30 [00:15<02:17,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.950769239001804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 4/30 [00:20<02:11,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0140631198883057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 5/30 [00:25<02:06,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4975806872049966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 6/30 [00:30<02:01,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1976337830225625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 7/30 [00:35<01:55,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9837774965498183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 8/30 [00:40<01:50,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8042560948265924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 9/30 [00:45<01:45,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6653809150060017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 10/30 [00:50<01:40,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5606728659735785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 11/30 [00:55<01:35,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4731748236550226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 12/30 [01:00<01:30,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4004019896189372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 13/30 [01:05<01:25,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3314256535636053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 14/30 [01:10<01:20,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2692345447010465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 15/30 [01:15<01:15,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2132419678899977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 16/30 [01:20<01:10,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1614938312106662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 17/30 [01:25<01:05,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1194183627764385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 18/30 [01:30<01:00,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.073613550927904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 19/30 [01:35<00:55,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0272055466969807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 20/30 [01:40<00:50,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9943109220928616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 21/30 [01:45<00:45,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9713623523712158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 22/30 [01:50<00:40,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9472174644470215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 23/30 [01:55<00:35,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9249449504746331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 24/30 [02:00<00:30,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9080767499075996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 25/30 [02:05<00:25,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8871663941277398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 26/30 [02:10<00:20,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8685512211587694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 27/30 [02:15<00:15,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8606519235504998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 28/30 [02:20<00:10,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8499305182033114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 29/30 [02:25<00:05,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8470937808354696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [02:30<00:00,  5.03s/it]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8153672218322754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 1/50 [00:05<04:05,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7792844573656718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 2/50 [00:10<04:01,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7619901100794474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 3/50 [00:15<03:56,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7458620468775431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 4/50 [00:20<03:51,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.735110859076182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 5/50 [00:25<03:45,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7279557320806715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 6/50 [00:30<03:40,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7241767512427436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 7/50 [00:35<03:35,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7196984026167128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 8/50 [00:40<03:32,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7160657379362318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 9/50 [00:45<03:26,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7135839329825507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 10/50 [00:50<03:21,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7124939560890198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 11/50 [00:55<03:16,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7107047438621521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 12/50 [01:00<03:11,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7069906062550015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 13/50 [01:05<03:06,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7073462870385911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 14/50 [01:10<03:01,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.705064038435618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 15/50 [01:15<02:56,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7048170765240988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 16/50 [01:20<02:51,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7029977507061429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 17/50 [01:25<02:45,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7005718946456909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 18/50 [01:30<02:40,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7005954186121622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 19/50 [01:35<02:35,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6998857723342048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 20/50 [01:40<02:30,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.697802311844296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 21/50 [01:45<02:25,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6972567174169753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 22/50 [01:50<02:20,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6959434747695923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 23/50 [01:55<02:15,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6957001884778341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 24/50 [02:00<02:10,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6944442192713419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 25/50 [02:05<02:05,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6936878032154508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 26/50 [02:10<02:00,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931205656793382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 27/50 [02:15<01:55,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6919044256210327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 28/50 [02:20<01:50,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6900553570853339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 29/50 [02:25<01:45,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.690370606051551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 30/50 [02:30<01:40,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.689636402659946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 31/50 [02:35<01:36,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6884917219479879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 32/50 [02:41<01:31,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875952018631829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 33/50 [02:46<01:25,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6869271265135871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 34/50 [02:51<01:20,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6864052613576254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 35/50 [02:56<01:15,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6865807705455356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 36/50 [03:01<01:10,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6861946251657274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 37/50 [03:06<01:05,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6844546066390144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 38/50 [03:11<01:00,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6828328106138442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 39/50 [03:16<00:55,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6821036140124003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 40/50 [03:21<00:50,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6825654771592882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 41/50 [03:26<00:45,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6816604402330186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 42/50 [03:31<00:40,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6812281277444627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 43/50 [03:36<00:35,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6807054148779975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 44/50 [03:41<00:30,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6804267830318875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 45/50 [03:46<00:25,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.679461936155955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 46/50 [03:51<00:20,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6791939602957832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 47/50 [03:56<00:15,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6779555545912849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 48/50 [04:01<00:10,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6786816186375089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 49/50 [04:06<00:05,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6769397854804993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [04:11<00:00,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6756658222940233\n",
      "Generating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization...\n",
      "computing Bleu score...\n",
      "computing METEOR score...\n",
      "computing Rouge score...\n",
      "computing CIDEr score...\n",
      "computing SPICE score...\n",
      "computing Universal_Sentence_Encoder_Similarity score...\n"
     ]
    }
   ],
   "source": [
    "caption_model1, model_score1 = cross_validation(cv[0][0], cv[0][1], 1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bleu_1': 0.5420602587634623,\n",
       " 'Bleu_2': 0.3944384687544192,\n",
       " 'Bleu_3': 0.3076348082784494,\n",
       " 'Bleu_4': 0.2505738856582193,\n",
       " 'METEOR': 0.2305141226280994,\n",
       " 'ROUGE_L': 0.44552871905314234,\n",
       " 'CIDEr': 1.2912744435619947,\n",
       " 'SPICE': 0.29100613954932025,\n",
       " 'USC_similarity': 0.516662359149365}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Split 2:\n",
      "Splitting data...\n",
      "8333 images for training and 2083 images for testing.\n",
      "There are 41665 captions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/8333 [00:00<03:23, 40.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed words 2688 ==> 916\n",
      "The vocabulary size is 917.\n",
      "819 out of 917 words are found in the pre-trained matrix.\n",
      "The size of embedding_matrix is (917, 500)\n",
      "Preparing dataloader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8333/8333 [03:26<00:00, 40.43it/s]\n",
      "  0%|          | 5/2083 [00:00<00:50, 40.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating set took: 0:03:26.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2083/2083 [00:50<00:00, 40.91it/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating set took: 0:00:50.92\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 1/30 [00:05<02:30,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.091214127010769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 2/30 [00:10<02:24,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.459252940283881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 3/30 [00:15<02:18,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.343069871266683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 4/30 [00:20<02:12,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6376596556769476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 5/30 [00:25<02:07,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.288652631971571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 6/30 [00:30<02:01,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0574027034971447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 7/30 [00:35<01:56,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8680434491899278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 8/30 [00:40<01:51,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7162432670593262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 9/30 [00:45<01:45,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.59210823641883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 10/30 [00:50<01:40,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4974021116892497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 11/30 [00:55<01:35,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4147374629974365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 12/30 [01:00<01:30,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3397164874606662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 13/30 [01:05<01:25,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.296516133679284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 14/30 [01:10<01:20,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.241160790125529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 15/30 [01:15<01:15,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1892808543311224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 16/30 [01:20<01:10,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1443513962957594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 17/30 [01:25<01:05,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1105898751152887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 18/30 [01:31<01:00,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0624175071716309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 19/30 [01:36<00:55,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0214061405923631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 20/30 [01:41<00:51,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0006959703233507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 21/30 [01:46<00:45,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9930688606368171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 22/30 [01:51<00:40,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9568179382218255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 23/30 [01:56<00:35,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9289791915151808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 24/30 [02:01<00:30,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9007644123501248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 25/30 [02:06<00:25,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8776506847805448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 26/30 [02:11<00:20,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854590098063151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 27/30 [02:16<00:15,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8444079160690308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 28/30 [02:21<00:10,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8314600321981642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 29/30 [02:26<00:05,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8261241383022733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [02:31<00:00,  5.06s/it]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8147941960228814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 1/50 [00:05<04:09,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8192484577496847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 2/50 [00:10<04:03,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7903589473830329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 3/50 [00:15<03:58,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76690188381407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 4/50 [00:20<03:53,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7525756557782491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 5/50 [00:25<03:47,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7418774565060934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 6/50 [00:30<03:42,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7377314700020684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 7/50 [00:35<03:37,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7326780226495531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 8/50 [00:40<03:32,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7292399009068807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 9/50 [00:45<03:27,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7260304358270433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 10/50 [00:50<03:22,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7236204213566251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 11/50 [00:55<03:17,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.721792995929718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 12/50 [01:00<03:11,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7212084333101908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 13/50 [01:05<03:06,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7189912133746676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 14/50 [01:10<03:02,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7185898688104417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 15/50 [01:15<02:56,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716882069905599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 16/50 [01:20<02:51,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715247200595008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 17/50 [01:25<02:46,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7139183216624789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 18/50 [01:30<02:41,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7146949768066406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 19/50 [01:36<02:36,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7119431959258186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 20/50 [01:41<02:31,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7110427882936265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 21/50 [01:46<02:27,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7108652657932706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 22/50 [01:51<02:22,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.709256629149119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 23/50 [01:56<02:17,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7081542213757833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 24/50 [02:01<02:12,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7077624996503195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 25/50 [02:06<02:07,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7072734898991055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 26/50 [02:11<02:02,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7070156203375922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 27/50 [02:16<01:57,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7060436341497633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 28/50 [02:21<01:51,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7042227586110433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 29/50 [02:26<01:46,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7046962115499709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 30/50 [02:32<01:41,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7028512292438083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 31/50 [02:37<01:36,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7030041548940871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 32/50 [02:42<01:31,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7022828658421835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 33/50 [02:47<01:26,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7005776696734958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 34/50 [02:52<01:21,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7006654474470351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 35/50 [02:57<01:16,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7010076642036438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 36/50 [03:02<01:11,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7008151147100661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 37/50 [03:07<01:05,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6992158757315742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 38/50 [03:12<01:01,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6985186272197299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 39/50 [03:17<00:55,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6977766619788276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 40/50 [03:22<00:50,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6975728604528639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 41/50 [03:27<00:45,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6970753073692322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 42/50 [03:33<00:40,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6960403852992587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 43/50 [03:38<00:35,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6954604453510709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 44/50 [03:43<00:30,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6934036943647597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 45/50 [03:48<00:25,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6939700841903687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 46/50 [03:53<00:20,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6940890351931254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 47/50 [03:58<00:15,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6939594878090752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 48/50 [04:03<00:10,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6932145092222426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 49/50 [04:08<00:05,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6923619641198052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [04:13<00:00,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6917287906010946\n",
      "Generating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization...\n",
      "computing Bleu score...\n",
      "computing METEOR score...\n",
      "computing Rouge score...\n",
      "computing CIDEr score...\n",
      "computing SPICE score...\n",
      "computing Universal_Sentence_Encoder_Similarity score...\n"
     ]
    }
   ],
   "source": [
    "caption_model2, model_score2 = cross_validation(cv[1][0], cv[1][1], 2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bleu_1': 0.5375623017670803,\n",
       " 'Bleu_2': 0.3963209404044298,\n",
       " 'Bleu_3': 0.3137641581215164,\n",
       " 'Bleu_4': 0.25951132713831176,\n",
       " 'METEOR': 0.23242995331745267,\n",
       " 'ROUGE_L': 0.4448378267442185,\n",
       " 'CIDEr': 1.3824513308578386,\n",
       " 'SPICE': 0.2936052517116219,\n",
       " 'USC_similarity': 0.5183357046342103}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Split 3:\n",
      "Splitting data...\n",
      "8333 images for training and 2083 images for testing.\n",
      "There are 41665 captions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/8333 [00:00<03:29, 39.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed words 2714 ==> 890\n",
      "The vocabulary size is 891.\n",
      "800 out of 891 words are found in the pre-trained matrix.\n",
      "The size of embedding_matrix is (891, 500)\n",
      "Preparing dataloader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8333/8333 [03:34<00:00, 38.91it/s]\n",
      "  0%|          | 5/2083 [00:00<00:49, 41.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating set took: 0:03:34.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2083/2083 [00:50<00:00, 40.93it/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating set took: 0:00:50.89\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 1/30 [00:05<02:27,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.036721600426568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 2/30 [00:10<02:22,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.386879603068034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 3/30 [00:15<02:17,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3394628365834556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 4/30 [00:20<02:12,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.674030754301283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 5/30 [00:25<02:07,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3253944185045032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 6/30 [00:30<02:02,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.079367068078783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 7/30 [00:35<01:56,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8835263384713068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 8/30 [00:40<01:51,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7291336721844144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 9/30 [00:45<01:46,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6153672403759427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 10/30 [00:50<01:41,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5121021138297186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 11/30 [00:55<01:36,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4272979233000014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 12/30 [01:01<01:31,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3595674435297649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 13/30 [01:06<01:26,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3143311606513128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 14/30 [01:11<01:21,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2530048025978937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 15/30 [01:16<01:16,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1955829991234674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 16/30 [01:21<01:11,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.137938380241394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 17/30 [01:26<01:06,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0924296114179823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 18/30 [01:31<01:00,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.060634930928548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 19/30 [01:36<00:55,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0312486953205533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 20/30 [01:41<00:51,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0055073499679565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 21/30 [01:47<00:46,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9789519111315409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 22/30 [01:52<00:40,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9509139723247952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 23/30 [01:57<00:35,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.920818911658393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 24/30 [02:02<00:30,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8975097669495476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 25/30 [02:07<00:25,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87204067574607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 26/30 [02:12<00:20,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8499553402264913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 27/30 [02:17<00:15,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8282274537616305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 28/30 [02:22<00:10,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8242297040091621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 29/30 [02:27<00:05,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825322601530287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [02:32<00:00,  5.09s/it]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8158903585539924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 1/50 [00:05<04:08,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7804175151718987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 2/50 [00:10<04:03,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7693461312188042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 3/50 [00:15<03:58,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7581641475359598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 4/50 [00:20<03:53,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7486639155281914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 5/50 [00:25<03:48,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7421289682388306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 6/50 [00:30<03:43,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7376696003807915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 7/50 [00:35<03:38,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7357618543836806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 8/50 [00:40<03:33,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7304403252071805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 9/50 [00:45<03:28,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7303104334407382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 10/50 [00:50<03:23,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7279243734147813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 11/50 [00:55<03:18,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7266147401597765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 12/50 [01:01<03:13,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7252599994341532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 13/50 [01:06<03:08,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7227727505895827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 14/50 [01:11<03:03,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7212232417530484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 15/50 [01:16<02:57,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7219040658738878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 16/50 [01:21<02:52,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.719433605670929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 17/50 [01:26<02:47,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7196785940064324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 18/50 [01:31<02:42,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7187272177802192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 19/50 [01:36<02:37,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7170231938362122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 20/50 [01:41<02:32,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7166860169834561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 21/50 [01:46<02:26,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7153201566802131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 22/50 [01:51<02:21,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7146689295768738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 23/50 [01:56<02:17,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7144653797149658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 24/50 [02:01<02:12,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7136024170451694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 25/50 [02:07<02:06,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7124623656272888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 26/50 [02:12<02:02,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7112024691369798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 27/50 [02:17<01:56,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7113759517669678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 28/50 [02:22<01:51,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7110510600937737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 29/50 [02:27<01:46,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7092278136147393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 30/50 [02:32<01:41,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7092705633905199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 31/50 [02:37<01:36,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7086585428979661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 32/50 [02:42<01:31,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.708018958568573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 33/50 [02:47<01:26,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.708020395702786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 34/50 [02:52<01:21,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7069007092052035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 35/50 [02:58<01:16,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7062425679630704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 36/50 [03:03<01:11,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7055293983883328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 37/50 [03:08<01:06,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7050903373294406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 38/50 [03:13<01:01,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7051776978704665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 39/50 [03:18<00:56,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7031147744920518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 40/50 [03:23<00:50,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7032250033484565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 41/50 [03:28<00:45,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7026833693186442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 42/50 [03:33<00:40,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7018557058440315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 43/50 [03:38<00:35,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7021646499633789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 44/50 [03:43<00:30,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7004023856586881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 45/50 [03:48<00:25,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7015586230489943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 46/50 [03:54<00:20,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6993337074915568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 47/50 [03:59<00:15,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6995649072859023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 48/50 [04:04<00:10,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6990793016221788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 49/50 [04:09<00:05,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6987208392884996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [04:14<00:00,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6988086965348985\n",
      "Generating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization...\n",
      "computing Bleu score...\n",
      "computing METEOR score...\n",
      "computing Rouge score...\n",
      "computing CIDEr score...\n",
      "computing SPICE score...\n",
      "computing Universal_Sentence_Encoder_Similarity score...\n"
     ]
    }
   ],
   "source": [
    "caption_model3, model_score3 = cross_validation(cv[2][0], cv[2][1], 3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bleu_1': 0.5400832668969554,\n",
       " 'Bleu_2': 0.40191724141601487,\n",
       " 'Bleu_3': 0.318971744032124,\n",
       " 'Bleu_4': 0.26263663111889174,\n",
       " 'METEOR': 0.24196269742096266,\n",
       " 'ROUGE_L': 0.4570226739274497,\n",
       " 'CIDEr': 1.4295462283110911,\n",
       " 'SPICE': 0.3058347075034665,\n",
       " 'USC_similarity': 0.5318594089282236}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Split 4:\n",
      "Splitting data...\n",
      "8333 images for training and 2083 images for testing.\n",
      "There are 41665 captions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/8333 [00:00<03:26, 40.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed words 2680 ==> 894\n",
      "The vocabulary size is 895.\n",
      "806 out of 895 words are found in the pre-trained matrix.\n",
      "The size of embedding_matrix is (895, 500)\n",
      "Preparing dataloader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8333/8333 [03:20<00:00, 41.47it/s]\n",
      "  0%|          | 5/2083 [00:00<00:49, 41.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating set took: 0:03:20.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2083/2083 [00:49<00:00, 41.70it/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating set took: 0:00:49.95\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 1/30 [00:05<02:26,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.931716018252903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 2/30 [00:10<02:21,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.994262589348687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 3/30 [00:15<02:16,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8860939343770347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 4/30 [00:20<02:11,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.420558902952406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 5/30 [00:25<02:06,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1264171070522733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 6/30 [00:30<02:01,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.905994971593221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 7/30 [00:35<01:57,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7428165409300063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 8/30 [00:40<01:52,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6276541948318481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 9/30 [00:45<01:46,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5124722454282973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 10/30 [00:50<01:41,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4189695914586384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 11/30 [00:55<01:36,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3381907675001357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 12/30 [01:00<01:31,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2806763119167752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 13/30 [01:06<01:26,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.237110608153873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 14/30 [01:11<01:21,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1755017042160034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 15/30 [01:16<01:16,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1233673095703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 16/30 [01:21<01:11,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.079861217074924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 17/30 [01:26<01:05,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0331070025761921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 18/30 [01:31<01:01,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9984408418337504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 19/30 [01:36<00:56,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9768891268306308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 20/30 [01:41<00:51,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9570923381381564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 21/30 [01:46<00:45,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9315115676985847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 22/30 [01:52<00:40,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892050994767083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 23/30 [01:57<00:35,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8604616589016385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 24/30 [02:02<00:30,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8314677874247233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 25/30 [02:07<00:25,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8134066727426317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 26/30 [02:12<00:20,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8025345537397597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 27/30 [02:17<00:15,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7791172001096938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 28/30 [02:22<00:10,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7654377023379008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 29/30 [02:27<00:05,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.750419921345181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [02:32<00:00,  5.09s/it]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7384402751922607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 1/50 [00:05<04:08,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.710514505704244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 2/50 [00:10<04:03,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7016627391179403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 3/50 [00:15<03:58,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6914570265346103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 4/50 [00:20<03:54,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6855711473359002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 5/50 [00:25<03:49,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6811454627248976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 6/50 [00:30<03:43,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6770553323957655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 7/50 [00:35<03:38,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6741738650533888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 8/50 [00:40<03:33,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6725365122159322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 9/50 [00:45<03:28,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6706080105569627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 10/50 [00:50<03:23,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6677229801813761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 11/50 [00:55<03:18,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.667349186208513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 12/50 [01:00<03:12,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6668997274504768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 13/50 [01:06<03:07,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6643171707789103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 14/50 [01:11<03:02,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6637296279271444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 15/50 [01:16<02:57,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6623561316066318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 16/50 [01:21<02:52,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6613907085524665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 17/50 [01:26<02:48,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6607281764348348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 18/50 [01:31<02:43,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6594557166099548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 19/50 [01:36<02:37,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6586964726448059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 20/50 [01:41<02:32,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6581335730022855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 21/50 [01:46<02:27,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6574283242225647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 22/50 [01:51<02:22,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.656683623790741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 23/50 [01:57<02:17,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6550869743029276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 24/50 [02:02<02:12,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6549529896842109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 25/50 [02:07<02:07,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6549978587362502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 26/50 [02:12<02:02,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6532548930909898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 27/50 [02:17<01:57,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6527515848477682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 28/50 [02:22<01:52,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.652550545003679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 29/50 [02:27<01:46,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6521298156844245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 30/50 [02:32<01:41,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6510079701741537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 31/50 [02:37<01:36,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6512129969067044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 32/50 [02:42<01:31,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6505772074063619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 33/50 [02:47<01:26,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6499259140756395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 34/50 [02:53<01:21,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6486457917425368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 35/50 [02:58<01:16,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6481686962975396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 36/50 [03:03<01:11,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6482349766625298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 37/50 [03:08<01:06,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6479015813933479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 38/50 [03:13<01:01,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6464860306845771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 39/50 [03:18<00:55,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6455076932907104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 40/50 [03:23<00:50,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6464807258711921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 41/50 [03:28<00:45,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6450430419709947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 42/50 [03:33<00:40,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6445123884412978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 43/50 [03:38<00:35,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6448164184888204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 44/50 [03:43<00:30,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6430481804741753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 45/50 [03:49<00:25,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6433997882737054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 46/50 [03:54<00:20,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6436279813448588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 47/50 [03:59<00:15,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6426680088043213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 48/50 [04:04<00:10,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6415058374404907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 49/50 [04:09<00:05,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6416170729531182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [04:14<00:00,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6413949728012085\n",
      "Generating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization...\n",
      "computing Bleu score...\n",
      "computing METEOR score...\n",
      "computing Rouge score...\n",
      "computing CIDEr score...\n",
      "computing SPICE score...\n",
      "computing Universal_Sentence_Encoder_Similarity score...\n"
     ]
    }
   ],
   "source": [
    "caption_model4, model_score4 = cross_validation(cv[3][0], cv[3][1], 4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bleu_1': 0.5385183575928508,\n",
       " 'Bleu_2': 0.401664355839296,\n",
       " 'Bleu_3': 0.31965552329358043,\n",
       " 'Bleu_4': 0.2636170076299316,\n",
       " 'METEOR': 0.24291759910549474,\n",
       " 'ROUGE_L': 0.453435001145289,\n",
       " 'CIDEr': 1.3581838537245277,\n",
       " 'SPICE': 0.3019722670054876,\n",
       " 'USC_similarity': 0.5283644756782876}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Split 5:\n",
      "Splitting data...\n",
      "8333 images for training and 2083 images for testing.\n",
      "There are 41665 captions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/8333 [00:00<03:39, 37.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed words 2657 ==> 905\n",
      "The vocabulary size is 906.\n",
      "815 out of 906 words are found in the pre-trained matrix.\n",
      "The size of embedding_matrix is (906, 500)\n",
      "Preparing dataloader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8333/8333 [03:37<00:00, 38.24it/s]\n",
      "  0%|          | 4/2083 [00:00<00:54, 38.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating set took: 0:03:37.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2083/2083 [00:55<00:00, 37.64it/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating set took: 0:00:55.34\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 1/30 [00:05<02:28,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.339605437384711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 2/30 [00:10<02:23,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.249551428688897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 3/30 [00:15<02:17,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2269477314419217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 4/30 [00:20<02:12,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6042593585120306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 5/30 [00:25<02:07,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2792451911502414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 6/30 [00:30<02:02,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.042784425947401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 7/30 [00:35<01:57,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8613771729999118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 8/30 [00:40<01:52,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.721433851453993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 9/30 [00:45<01:47,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.600182228618198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 10/30 [00:50<01:41,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.508430626657274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 11/30 [00:56<01:36,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4327043559816148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 12/30 [01:01<01:31,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.354536188973321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 13/30 [01:06<01:26,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2796898285547893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 14/30 [01:11<01:21,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2129360834757488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 15/30 [01:16<01:16,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.151537471347385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 16/30 [01:21<01:11,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.105354905128479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 17/30 [01:26<01:06,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0664195948176913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 18/30 [01:31<01:01,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0317992965380351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 19/30 [01:37<00:56,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9967821968926324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 20/30 [01:42<00:51,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.962202231089274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 21/30 [01:47<00:45,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9288284844822354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 22/30 [01:52<00:40,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9204189512464735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 23/30 [01:57<00:35,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9239352676603529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 24/30 [02:02<00:30,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9014716810650296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 25/30 [02:07<00:25,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8708501590622796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 26/30 [02:12<00:20,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333869510226779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 27/30 [02:18<00:15,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8048171798388163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 28/30 [02:23<00:10,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.780169771777259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 29/30 [02:28<00:05,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7688845462269254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [02:33<00:00,  5.11s/it]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7604452504052056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 1/50 [00:05<04:10,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7265607251061333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 2/50 [00:10<04:05,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7118180063035753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 3/50 [00:15<04:00,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6999521719084846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 4/50 [00:20<03:55,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6924256417486403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 5/50 [00:25<03:49,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6886884636349149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 6/50 [00:30<03:44,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6858535872565376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 7/50 [00:35<03:39,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6831332908736335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 8/50 [00:40<03:34,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6812933617168002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 9/50 [00:45<03:28,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6811629666222466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 10/50 [00:51<03:24,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.678140229649014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 11/50 [00:56<03:19,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6779323021570841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 12/50 [01:01<03:13,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6772496435377333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 13/50 [01:06<03:08,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6750216219160292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 14/50 [01:11<03:03,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6760129928588867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 15/50 [01:16<02:58,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6742182903819613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 16/50 [01:21<02:53,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6728075610266792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 17/50 [01:26<02:48,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6724045938915677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 18/50 [01:31<02:43,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6707708835601807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 19/50 [01:37<02:38,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.670495867729187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 20/50 [01:42<02:33,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6692971587181091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 21/50 [01:47<02:27,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6697915527555678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 22/50 [01:52<02:23,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6686988340483772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 23/50 [01:57<02:18,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6672963831159804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 24/50 [02:02<02:13,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6678453087806702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 25/50 [02:07<02:07,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6670043733384874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 26/50 [02:12<02:02,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6664998133977255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 27/50 [02:17<01:57,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6653041574690077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 28/50 [02:23<01:52,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664207829369439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 29/50 [02:28<01:47,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6644598311848111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 30/50 [02:33<01:42,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6637970407803854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 31/50 [02:38<01:37,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6634748776753744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 32/50 [02:43<01:31,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6622439622879028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 33/50 [02:48<01:26,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6621544029977586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 34/50 [02:53<01:21,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6612168881628249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 35/50 [02:58<01:16,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6610119673940871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 36/50 [03:03<01:11,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6612032585673862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 37/50 [03:09<01:06,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6605443822013007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 38/50 [03:14<01:01,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6595233082771301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 39/50 [03:19<00:56,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6597828798823886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 40/50 [03:24<00:51,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6591713362269931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 41/50 [03:29<00:46,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6582615640428331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 42/50 [03:34<00:40,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6581878463427225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 43/50 [03:39<00:35,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6576003630956014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 44/50 [03:44<00:30,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6575357516606649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 45/50 [03:49<00:25,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6565239826838175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 46/50 [03:55<00:20,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6564567751354642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 47/50 [04:00<00:15,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.655600110689799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 48/50 [04:05<00:10,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6549380554093255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 49/50 [04:10<00:05,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6546445157792833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [04:15<00:00,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6542874972025553\n",
      "Generating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization...\n",
      "computing Bleu score...\n",
      "computing METEOR score...\n",
      "computing Rouge score...\n",
      "computing CIDEr score...\n",
      "computing SPICE score...\n",
      "computing Universal_Sentence_Encoder_Similarity score...\n"
     ]
    }
   ],
   "source": [
    "caption_model5, model_score5 = cross_validation(cv[4][0], cv[4][1], 5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bleu_1': 0.5391378843899116,\n",
       " 'Bleu_2': 0.40305377539010917,\n",
       " 'Bleu_3': 0.3223556718709861,\n",
       " 'Bleu_4': 0.2683234256507227,\n",
       " 'METEOR': 0.23510841121944365,\n",
       " 'ROUGE_L': 0.44604607276402924,\n",
       " 'CIDEr': 1.3759996137393877,\n",
       " 'SPICE': 0.2893594562940821,\n",
       " 'USC_similarity': 0.5212505211899853}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = defaultdict(list)\n",
    "for scores in [model_score1, model_score2, model_score3, model_score4, model_score5]:\n",
    "    for key, value in scores.items():\n",
    "        model_scores[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'Bleu_1': [0.5420602587634623,\n",
       "              0.5375623017670803,\n",
       "              0.5400832668969554,\n",
       "              0.5385183575928508,\n",
       "              0.5391378843899116],\n",
       "             'Bleu_2': [0.3944384687544192,\n",
       "              0.3963209404044298,\n",
       "              0.40191724141601487,\n",
       "              0.401664355839296,\n",
       "              0.40305377539010917],\n",
       "             'Bleu_3': [0.3076348082784494,\n",
       "              0.3137641581215164,\n",
       "              0.318971744032124,\n",
       "              0.31965552329358043,\n",
       "              0.3223556718709861],\n",
       "             'Bleu_4': [0.2505738856582193,\n",
       "              0.25951132713831176,\n",
       "              0.26263663111889174,\n",
       "              0.2636170076299316,\n",
       "              0.2683234256507227],\n",
       "             'METEOR': [0.2305141226280994,\n",
       "              0.23242995331745267,\n",
       "              0.24196269742096266,\n",
       "              0.24291759910549474,\n",
       "              0.23510841121944365],\n",
       "             'ROUGE_L': [0.44552871905314234,\n",
       "              0.4448378267442185,\n",
       "              0.4570226739274497,\n",
       "              0.453435001145289,\n",
       "              0.44604607276402924],\n",
       "             'CIDEr': [1.2912744435619947,\n",
       "              1.3824513308578386,\n",
       "              1.4295462283110911,\n",
       "              1.3581838537245277,\n",
       "              1.3759996137393877],\n",
       "             'SPICE': [0.29100613954932025,\n",
       "              0.2936052517116219,\n",
       "              0.3058347075034665,\n",
       "              0.3019722670054876,\n",
       "              0.2893594562940821],\n",
       "             'USC_similarity': [0.516662359149365,\n",
       "              0.5183357046342103,\n",
       "              0.5318594089282236,\n",
       "              0.5283644756782876,\n",
       "              0.5212505211899853]})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = '15.1'\n",
    "with open(f'{root_captioning}/fz_notebooks/cv_n{tag}.json', 'w') as fp:\n",
    "    json.dump(model_scores, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "9-fz-baseline_model_pytorch_v3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}