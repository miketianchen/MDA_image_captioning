{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10921 images in the rsicd dataset.\n",
      "There are 2100 images in the ucm dataset.\n",
      "There are 613 images in the sydney dataset.\n"
     ]
    }
   ],
   "source": [
    "json_data = {}\n",
    "sizes = {}\n",
    "set_name = ['rsicd', 'ucm', 'sydney']\n",
    "\n",
    "# read in json files from all three datasets\n",
    "for name in set_name:\n",
    "    with open('../data/raw/dataset_' + name + '_modified.json', 'r') as data:\n",
    "        json_data[name] = json.load(data)\n",
    "        sizes[name] = len(json_data[name]['images'])\n",
    "        print(f'There are {sizes[name]} images in the {name} dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13634"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_size = sum(list(sizes.values()))\n",
    "total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create splits based on a sequence from 0 to 13633\n",
    "# an image from the RSCID dataset has a index in [0, 10920]\n",
    "# an image from the UCM dataset has a index in [10921, 13020]\n",
    "# an image from the Sydney dataset has a index in [13021, 13633]\n",
    "train_valid, test = train_test_split(np.arange(sum(list(sizes.values()))), test_size=0.2, random_state=123)\n",
    "train, valid = train_test_split(train_valid, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8725"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2727"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2182"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(seqs, label):\n",
    "    \"\"\"\n",
    "    Extracts image information for the training, validation,\n",
    "    or test dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    ------------\n",
    "    seqs: numpy.ndarray\n",
    "        the indexes for the dataset\n",
    "    label: str\n",
    "        the name of the dataset\n",
    "        \n",
    "    Return:\n",
    "    --------\n",
    "    dict\n",
    "        a dict with image infromation with the following \n",
    "        structure: \n",
    "        {dataset name (one of 'rsicd', 'ucm' and 'sydney'): \n",
    "            {\n",
    "                filename (in the format of *.tif or *.jpeg): \n",
    "                dict of the img info\n",
    "            }\n",
    "        \n",
    "        }\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def aggerate(x, ind, name):\n",
    "        \"\"\"\n",
    "        Aggerates image information.\n",
    "\n",
    "        Parameters:\n",
    "        ------------\n",
    "        x: dict\n",
    "            the dict to store image information\n",
    "        ind: int\n",
    "            the index of the image in the dataset\n",
    "        name: str\n",
    "            the name of the dataset \n",
    "            (one of 'rsicd', 'ucm' and 'sydney')\n",
    "        Return:\n",
    "        --------\n",
    "        dict\n",
    "            x\n",
    "        \"\"\"\n",
    "        x[json_data[name]['images'][ind]['filename']] = json_data[name]['images'][ind]\n",
    "        return x\n",
    "    \n",
    "    print()\n",
    "    print(f'Preparing the {label} dataset:')\n",
    "\n",
    "    imgs = {}\n",
    "    \n",
    "    imgs['rsicd'] = reduce(lambda x, y: aggerate(x, y, 'rsicd'),\n",
    "                           seqs[seqs < sizes['rsicd']], {})\n",
    "    \n",
    "    imgs['ucm'] = reduce(lambda x, y: aggerate(x, y - sizes['rsicd'], 'ucm'),\n",
    "                         seqs[(seqs >= sizes['rsicd']) & (seqs < sizes['rsicd'] + sizes['ucm'])], {})\n",
    "    \n",
    "    imgs['sydney'] = reduce(lambda x, y: aggerate(x, y - sizes['rsicd'] - sizes['ucm'], 'sydney'),\n",
    "                            seqs[sizes['rsicd'] + sizes['ucm'] <= seqs], {})\n",
    "\n",
    "    print(f\"{len(imgs['rsicd'])} images from the RSICD dataset\")\n",
    "    print(f\"{len(imgs['ucm'])} images from the UCM dataset\")\n",
    "    print(f\"{len(imgs['sydney'])} images from the Sydney dataset\")\n",
    "    print(f\"{len(imgs['rsicd']) + len(imgs['ucm']) + len(imgs['sydney'])} images in total\")\n",
    "\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing the training dataset:\n",
      "6990 images from the RSICD dataset\n",
      "1338 images from the UCM dataset\n",
      "397 images from the Sydney dataset\n",
      "8725 images in total\n"
     ]
    }
   ],
   "source": [
    "train_imgs = split_data(train, 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing the validation dataset:\n",
      "1735 images from the RSICD dataset\n",
      "345 images from the UCM dataset\n",
      "102 images from the Sydney dataset\n",
      "2182 images in total\n"
     ]
    }
   ],
   "source": [
    "valid_imgs = split_data(valid, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing the test dataset:\n",
      "2196 images from the RSICD dataset\n",
      "417 images from the UCM dataset\n",
      "114 images from the Sydney dataset\n",
      "2727 images in total\n"
     ]
    }
   ],
   "source": [
    "test_imgs = split_data(test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_names = [(train_imgs, 'train', train), \n",
    "              (valid_imgs, 'valid', valid), \n",
    "              (test_imgs, 'test', test)]\n",
    "\n",
    "# test the split_data function\n",
    "for imgs, name, seq in imgs_names:\n",
    "    \n",
    "    for key in set_name:\n",
    "        assert len(set((imgs[key].keys()))) == len(list(imgs[key].keys())),\\\n",
    "        f'There is duplicated image from the {key} dataset in the {name} dataset.' \n",
    "        \n",
    "    assert len(seq) == sum([len(list(imgs[key].keys())) for key in set_name]),\\\n",
    "        f'The number of the {name} images does not match the size of the {name} dataset.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs, name, _ in imgs_names:\n",
    "    with open('../data/interim/' + name + '.json', 'w') as file:\n",
    "        json.dump(imgs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
