{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.append('../scr/evaluation/')\n",
    "from eval_model import eval_model\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference captions\n",
    "ref_path = '../data/processed/json/'\n",
    "with open(ref_path + 'valid.json', 'r') as jsonFile:\n",
    "    ref = json.load(jsonFile)\n",
    "    \n",
    "# generated captions\n",
    "results_path = '../models'\n",
    "results = []\n",
    "for tag in ['9.1.2', '9.3', '11.1', '11.2', '14', '15']:\n",
    "    with open(f'{results_path}/test_results_n{tag}.json', 'r') as f:\n",
    "        results.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization...\n",
      "computing Bleu score...\n",
      "computing METEOR score...\n",
      "computing Rouge score...\n",
      "computing CIDEr score...\n",
      "computing SPICE score...\n",
      "computing Universal_Sentence_Encoder_Similarity score...\n",
      "tokenization...\n",
      "computing Bleu score...\n",
      "computing METEOR score...\n",
      "computing Rouge score...\n",
      "computing CIDEr score...\n",
      "computing SPICE score...\n",
      "computing Universal_Sentence_Encoder_Similarity score...\n",
      "tokenization...\n",
      "computing Bleu score...\n",
      "computing METEOR score...\n",
      "computing Rouge score...\n",
      "computing CIDEr score...\n",
      "computing SPICE score...\n",
      "computing Universal_Sentence_Encoder_Similarity score...\n",
      "tokenization...\n",
      "computing Bleu score...\n",
      "computing METEOR score...\n",
      "computing Rouge score...\n",
      "computing CIDEr score...\n",
      "computing SPICE score...\n",
      "computing Universal_Sentence_Encoder_Similarity score...\n",
      "tokenization...\n",
      "computing Bleu score...\n",
      "computing METEOR score...\n",
      "computing Rouge score...\n",
      "computing CIDEr score...\n",
      "computing SPICE score...\n",
      "computing Universal_Sentence_Encoder_Similarity score...\n",
      "tokenization...\n",
      "computing Bleu score...\n",
      "computing METEOR score...\n",
      "computing Rouge score...\n",
      "computing CIDEr score...\n",
      "computing SPICE score...\n",
      "computing Universal_Sentence_Encoder_Similarity score...\n"
     ]
    }
   ],
   "source": [
    "model_score_list = []\n",
    "img_score_list = []\n",
    "score_by_metrics_list = [] \n",
    "for i in range(len(results)):\n",
    "    model_score, img_score, score_by_metrics = eval_model(ref, results[i])\n",
    "    model_score_list.append(model_score)\n",
    "    img_score_list.append(img_score)    \n",
    "    score_by_metrics_list.append(score_by_metrics)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = defaultdict(list)\n",
    "for i in range(len(results)):\n",
    "    for key, value in model_score_list[i].items():\n",
    "        model_scores[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bleu_1</th>\n",
       "      <th>Bleu_2</th>\n",
       "      <th>Bleu_3</th>\n",
       "      <th>Bleu_4</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>ROUGE_L</th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "      <th>USC_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.583513</td>\n",
       "      <td>0.453358</td>\n",
       "      <td>0.371907</td>\n",
       "      <td>0.314094</td>\n",
       "      <td>0.266576</td>\n",
       "      <td>0.497653</td>\n",
       "      <td>1.665167</td>\n",
       "      <td>0.335762</td>\n",
       "      <td>0.565650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.557826</td>\n",
       "      <td>0.420189</td>\n",
       "      <td>0.336305</td>\n",
       "      <td>0.279290</td>\n",
       "      <td>0.249395</td>\n",
       "      <td>0.471584</td>\n",
       "      <td>1.546761</td>\n",
       "      <td>0.313963</td>\n",
       "      <td>0.550267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.518231</td>\n",
       "      <td>0.382955</td>\n",
       "      <td>0.302777</td>\n",
       "      <td>0.249798</td>\n",
       "      <td>0.238768</td>\n",
       "      <td>0.443589</td>\n",
       "      <td>1.341812</td>\n",
       "      <td>0.298603</td>\n",
       "      <td>0.523359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.581097</td>\n",
       "      <td>0.446476</td>\n",
       "      <td>0.361896</td>\n",
       "      <td>0.302204</td>\n",
       "      <td>0.254460</td>\n",
       "      <td>0.485667</td>\n",
       "      <td>1.590656</td>\n",
       "      <td>0.327023</td>\n",
       "      <td>0.557232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.542706</td>\n",
       "      <td>0.403990</td>\n",
       "      <td>0.320006</td>\n",
       "      <td>0.262865</td>\n",
       "      <td>0.241193</td>\n",
       "      <td>0.456672</td>\n",
       "      <td>1.421833</td>\n",
       "      <td>0.304242</td>\n",
       "      <td>0.529937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.572690</td>\n",
       "      <td>0.438470</td>\n",
       "      <td>0.354843</td>\n",
       "      <td>0.296173</td>\n",
       "      <td>0.254999</td>\n",
       "      <td>0.479851</td>\n",
       "      <td>1.572338</td>\n",
       "      <td>0.322854</td>\n",
       "      <td>0.551468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bleu_1    Bleu_2    Bleu_3    Bleu_4    METEOR   ROUGE_L     CIDEr  \\\n",
       "0  0.583513  0.453358  0.371907  0.314094  0.266576  0.497653  1.665167   \n",
       "1  0.557826  0.420189  0.336305  0.279290  0.249395  0.471584  1.546761   \n",
       "2  0.518231  0.382955  0.302777  0.249798  0.238768  0.443589  1.341812   \n",
       "3  0.581097  0.446476  0.361896  0.302204  0.254460  0.485667  1.590656   \n",
       "4  0.542706  0.403990  0.320006  0.262865  0.241193  0.456672  1.421833   \n",
       "5  0.572690  0.438470  0.354843  0.296173  0.254999  0.479851  1.572338   \n",
       "\n",
       "      SPICE  USC_similarity  \n",
       "0  0.335762        0.565650  \n",
       "1  0.313963        0.550267  \n",
       "2  0.298603        0.523359  \n",
       "3  0.327023        0.557232  \n",
       "4  0.304242        0.529937  \n",
       "5  0.322854        0.551468  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bleu_1': 0.583513318934459,\n",
       " 'Bleu_2': 0.45335796027535147,\n",
       " 'Bleu_3': 0.3719070652434968,\n",
       " 'Bleu_4': 0.3140939789802509,\n",
       " 'METEOR': 0.2665764264435539,\n",
       " 'ROUGE_L': 0.49765285060171416,\n",
       " 'CIDEr': 1.6651665243407117,\n",
       " 'SPICE': 0.33576189307244253,\n",
       " 'USC_similarity': 0.5656497148515374}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bleu_1': 0.583513318934459,\n",
       " 'Bleu_2': 0.45335796027535147,\n",
       " 'Bleu_3': 0.3719070652434968,\n",
       " 'Bleu_4': 0.3140939789802509,\n",
       " 'METEOR': 0.2665764264435539,\n",
       " 'ROUGE_L': 0.49765285060171416,\n",
       " 'CIDEr': 1.6651665243407117,\n",
       " 'SPICE': 0.33576189307244253,\n",
       " 'USC_similarity': 0.5656497141883499}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_list[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
